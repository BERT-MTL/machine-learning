{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOp3sa27QIzWfEO6CiCMfTj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3fdc2470c953429ca98df0a667a59f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_527ebc6c429c4f33abd61b176fb1797b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b6956b02e014492cbdf2577cd82a941c",
              "IPY_MODEL_4385c2146bac48cbb3eca5f8d6b35d3c"
            ]
          }
        },
        "527ebc6c429c4f33abd61b176fb1797b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6956b02e014492cbdf2577cd82a941c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_920f352577ee4f02bdb2b931e4442f45",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb64f2371ebf405bbb34a2ac6db3d428"
          }
        },
        "4385c2146bac48cbb3eca5f8d6b35d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_51eec80b667145a2b963cd3802af3164",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 725kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f7d03db90304e91abc6e8c7d27b547e"
          }
        },
        "920f352577ee4f02bdb2b931e4442f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb64f2371ebf405bbb34a2ac6db3d428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51eec80b667145a2b963cd3802af3164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f7d03db90304e91abc6e8c7d27b547e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0cae6134c38406a99b5f00a3a2afc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_39f6103c61224fac8db9829318d5fff8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cd237248c0f84ff1aa8849056f806390",
              "IPY_MODEL_0215105f62af4f43877c253dc2731cc6"
            ]
          }
        },
        "39f6103c61224fac8db9829318d5fff8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd237248c0f84ff1aa8849056f806390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0ce5dcead073466fae08a02789511777",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_421e40fe86ad4d50a611fbafd3486bb4"
          }
        },
        "0215105f62af4f43877c253dc2731cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76e728feac1a45ddac2fa7d8399dcf8a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 146B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a62b5923794d4030a7960ad05fb6e205"
          }
        },
        "0ce5dcead073466fae08a02789511777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "421e40fe86ad4d50a611fbafd3486bb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76e728feac1a45ddac2fa7d8399dcf8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a62b5923794d4030a7960ad05fb6e205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97ade3ca6db94712acb8c5b7564da52b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a919708b5884846a54197e49a0bdae9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8542730f21444177b243862e5994f808",
              "IPY_MODEL_6ad6c29519f44beb999ef2e09cf008d8"
            ]
          }
        },
        "3a919708b5884846a54197e49a0bdae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8542730f21444177b243862e5994f808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0dba1678a2004122ad3a090d18f67334",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2dae36d666f4cadab6d086d5d020d8d"
          }
        },
        "6ad6c29519f44beb999ef2e09cf008d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3adb285bf1aa4557b7bf2ffe32ce0c02",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 5.40MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bff65a15b594473eae624ec3ea74017f"
          }
        },
        "0dba1678a2004122ad3a090d18f67334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2dae36d666f4cadab6d086d5d020d8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3adb285bf1aa4557b7bf2ffe32ce0c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bff65a15b594473eae624ec3ea74017f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56eccfed00274f89b22d7380b7e33de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_268a9afe72d742bebef9b36c9189df4e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c39dd5bfe3ec4de2adcb7e2e7d86cc1b",
              "IPY_MODEL_2d28b2117a304fcb87f645d672b95bc0"
            ]
          }
        },
        "268a9afe72d742bebef9b36c9189df4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c39dd5bfe3ec4de2adcb7e2e7d86cc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4e6404706ca94e79bfdf6f7d3277c786",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2af6ca4c8479420489a805a811cef2a6"
          }
        },
        "2d28b2117a304fcb87f645d672b95bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b56b2feec154cdda7d9776ebbf8d398",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 5.92kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28411a1669bf4c609ed48dc2318362ef"
          }
        },
        "4e6404706ca94e79bfdf6f7d3277c786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2af6ca4c8479420489a805a811cef2a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b56b2feec154cdda7d9776ebbf8d398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28411a1669bf4c609ed48dc2318362ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "279fbc4b754e4645b9a8a90dcabb4717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a66ad1c0c775479eaf1efa189b84cd80",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a2fea0e68d7c4554b3dc97c384edd2ef",
              "IPY_MODEL_a1d6d6c52d4344f98a91b757dba28236"
            ]
          }
        },
        "a66ad1c0c775479eaf1efa189b84cd80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2fea0e68d7c4554b3dc97c384edd2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9878e513ab1148a8b4e660d6e460c67a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_936369bc406a4a0893ab8cb271a2a1cc"
          }
        },
        "a1d6d6c52d4344f98a91b757dba28236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eeae0ec8513d4a86918c57d58f21bea9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 50.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7202124401ca40668df1e084efcb7cf3"
          }
        },
        "9878e513ab1148a8b4e660d6e460c67a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "936369bc406a4a0893ab8cb271a2a1cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eeae0ec8513d4a86918c57d58f21bea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7202124401ca40668df1e084efcb7cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManilPatel777/machine-learning/blob/main/Untitled13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcGcgPVYocEv",
        "outputId": "89c65b4b-56d0-4802-f3e9-580fa3657ce7"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\r\u001b[K     |▏                               | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 29.7MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 22.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 26.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 25.5MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 28.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 18.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 81kB 19.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92kB 17.9MB/s eta 0:00:01\r\u001b[K     |█▋                              | 102kB 18.0MB/s eta 0:00:01\r\u001b[K     |█▉                              | 112kB 18.0MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 18.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 133kB 18.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 143kB 18.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 153kB 18.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 163kB 18.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 174kB 18.0MB/s eta 0:00:01\r\u001b[K     |███                             | 184kB 18.0MB/s eta 0:00:01\r\u001b[K     |███▏                            | 194kB 18.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 204kB 18.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 215kB 18.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 225kB 18.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 235kB 18.0MB/s eta 0:00:01\r\u001b[K     |████                            | 245kB 18.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 256kB 18.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 266kB 18.0MB/s eta 0:00:01\r\u001b[K     |████▌                           | 276kB 18.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 286kB 18.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 296kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 307kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 317kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 327kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 337kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 348kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 358kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 368kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 378kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 389kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 399kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 409kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 419kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 430kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 440kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 450kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 460kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 471kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 481kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 491kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 501kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 512kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 522kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 532kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 542kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 552kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 563kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 573kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 583kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 593kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 604kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 614kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 624kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 634kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 645kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 655kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 665kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 675kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 686kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 696kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 706kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 716kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 727kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 737kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 747kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 757kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 768kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 778kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 788kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 798kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 808kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 819kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 829kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 839kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 849kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 860kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 870kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 880kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 890kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 901kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 911kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 921kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 931kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 942kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 952kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 962kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 972kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 983kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 993kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.0MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.0MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.0MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.0MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.2MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.2MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.2MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.2MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.2MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.3MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.3MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.3MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.3MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.3MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.3MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.4MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.4MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.4MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.4MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.4MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.4MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.4MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.4MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.5MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.5MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.5MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.5MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.5MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.5MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.5MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.6MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.6MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.6MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.6MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.6MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.6MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.6MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.6MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.6MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.7MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.7MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.7MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.7MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.7MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.7MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.7MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.8MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.8MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.8MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.8MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.8MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.8MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.8MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.8MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.9MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.9MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.9MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.9MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.9MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.9MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.9MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.9MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.9MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.0MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.0MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.0MB 18.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 54.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=22859aad2f8f03a196dd8a49da55be6c987b167c6f99e306312418a36cf585bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9hnYXthoev0"
      },
      "source": [
        "# Importing stock ml libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lJnf3iEohzx",
        "outputId": "04bc041d-8e09-4eb6-a165-cd27a2abbbf0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb569035430>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnWMmajxrbIK"
      },
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8LhDMtXonB3",
        "outputId": "bb1dc126-7f99-4803-8dcf-043ee2cf350b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "OVB7PAi_oqZ0",
        "outputId": "5acedfee-2cf5-4b01-d7b3-b51c3d4ff28b"
      },
      "source": [
        "df_te = pd.read_csv('/content/drive/My Drive/revisedATSA.csv')\n",
        "df_te = df_te.rename(columns={'sentence': 'text', 'aspect': 'aspect_term', 'sentiment': 'Class'})\n",
        "df_te.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the bread is top notch as well.</td>\n",
              "      <td>bread</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i have to say they have one of the fastest del...</td>\n",
              "      <td>delivery times</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food is always fresh and hot- ready to eat!</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>did i mention that the coffee is outstanding?</td>\n",
              "      <td>coffee</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>certainly not the best sushi in new york, howe...</td>\n",
              "      <td>place</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text     aspect_term     Class\n",
              "0                    the bread is top notch as well.           bread  positive\n",
              "1  i have to say they have one of the fastest del...  delivery times  positive\n",
              "2        food is always fresh and hot- ready to eat!            food  positive\n",
              "3      did i mention that the coffee is outstanding?          coffee  positive\n",
              "4  certainly not the best sushi in new york, howe...           place  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXNbcGtm0kPi",
        "outputId": "f16c531f-a4fd-4ee5-df27-a0dfe3755194"
      },
      "source": [
        "df_te.Class.count()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ltZiZOO9o6iv",
        "outputId": "f6f3ecd0-de43-4920-a03e-a39cca9ddda5"
      },
      "source": [
        "#df_te = df_te.drop(df_te.index[df_te['Class'] == 'conflict'], inplace = True)\n",
        "#df_te.Class = df_te.Class.replace('conflict', 'neutral') \n",
        "df_test = df_te\n",
        "df_test.shape\n",
        "df_test.head(50)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the bread is top notch as well.</td>\n",
              "      <td>bread</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i have to say they have one of the fastest del...</td>\n",
              "      <td>delivery times</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food is always fresh and hot- ready to eat!</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>did i mention that the coffee is outstanding?</td>\n",
              "      <td>coffee</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>certainly not the best sushi in new york, howe...</td>\n",
              "      <td>place</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i trust the people at go sushi, it never disap...</td>\n",
              "      <td>people</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>straight-forward, no surprises, very decent ja...</td>\n",
              "      <td>japanese food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>best spicy tuna roll, great asian salad.</td>\n",
              "      <td>asian salad</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>best spicy tuna roll, great asian salad.</td>\n",
              "      <td>spicy tuna roll</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>try the rose roll (not on menu).</td>\n",
              "      <td>rose roll</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>try the rose roll (not on menu).</td>\n",
              "      <td>menu</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>drinks</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>lychee martini</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>in fact, this was not a nicoise salad and was ...</td>\n",
              "      <td>nicoise salad</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>menu</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>drinks</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>dessert pizza</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>once we sailed, the top-notch food and live en...</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>once we sailed, the top-notch food and live en...</td>\n",
              "      <td>live entertainment</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>our waiter was horrible; so rude and disintere...</td>\n",
              "      <td>waiter</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>the sangria's - watered down.</td>\n",
              "      <td>sangria</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>menu - uneventful, small.</td>\n",
              "      <td>menu</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>anytime and everytime i find myself in the nei...</td>\n",
              "      <td>sushi</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>anytime and everytime i find myself in the nei...</td>\n",
              "      <td>portions</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>anytime and everytime i find myself in the nei...</td>\n",
              "      <td>price</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>great food but the service was dreadful!</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>great food but the service was dreadful!</td>\n",
              "      <td>service</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>the portions of the food that came out were me...</td>\n",
              "      <td>portions of the food</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>the two waitress's looked like they had been s...</td>\n",
              "      <td>waitress's</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>from the beginning, we were met by friendly st...</td>\n",
              "      <td>staff memebers</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>from the beginning, we were met by friendly st...</td>\n",
              "      <td>parking</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>we enjoyed ourselves thoroughly and will be go...</td>\n",
              "      <td>desserts</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>desserts are almost incredible: my personal fa...</td>\n",
              "      <td>desserts</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>desserts are almost incredible: my personal fa...</td>\n",
              "      <td>tart of the day</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>the food was extremely tasty, creatively prese...</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>the food was extremely tasty, creatively prese...</td>\n",
              "      <td>wine</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>the lasagna was probably the best i have tasted.</td>\n",
              "      <td>lasagna</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>harumi sushi has the freshest and most delicio...</td>\n",
              "      <td>array of sushi</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>i highly recommend it for not just its superb ...</td>\n",
              "      <td>cuisine</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>i highly recommend it for not just its superb ...</td>\n",
              "      <td>owners</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>i highly recommend it for not just its superb ...</td>\n",
              "      <td>staff</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>if you're craving some serious indian food and...</td>\n",
              "      <td>indian food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>if you're craving some serious indian food and...</td>\n",
              "      <td>ambiance</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>i definitely enjoyed the food as well.</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>service</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>garden</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>food</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>appetizers</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>entrees</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text  ...     Class\n",
              "0                     the bread is top notch as well.  ...  positive\n",
              "1   i have to say they have one of the fastest del...  ...  positive\n",
              "2         food is always fresh and hot- ready to eat!  ...  positive\n",
              "3       did i mention that the coffee is outstanding?  ...  positive\n",
              "4   certainly not the best sushi in new york, howe...  ...  positive\n",
              "5   i trust the people at go sushi, it never disap...  ...  positive\n",
              "6   straight-forward, no surprises, very decent ja...  ...  positive\n",
              "7            best spicy tuna roll, great asian salad.  ...  positive\n",
              "8            best spicy tuna roll, great asian salad.  ...  positive\n",
              "9                    try the rose roll (not on menu).  ...  positive\n",
              "10                   try the rose roll (not on menu).  ...   neutral\n",
              "11  i love the drinks, esp lychee martini, and the...  ...  positive\n",
              "12  i love the drinks, esp lychee martini, and the...  ...  positive\n",
              "13  i love the drinks, esp lychee martini, and the...  ...  positive\n",
              "14  in fact, this was not a nicoise salad and was ...  ...  negative\n",
              "15  while there's a decent menu, it shouldn't take...  ...  positive\n",
              "16  while there's a decent menu, it shouldn't take...  ...   neutral\n",
              "17  while there's a decent menu, it shouldn't take...  ...   neutral\n",
              "18  once we sailed, the top-notch food and live en...  ...  positive\n",
              "19  once we sailed, the top-notch food and live en...  ...  positive\n",
              "20  our waiter was horrible; so rude and disintere...  ...  negative\n",
              "21                      the sangria's - watered down.  ...  negative\n",
              "22                          menu - uneventful, small.  ...  negative\n",
              "23  anytime and everytime i find myself in the nei...  ...  positive\n",
              "24  anytime and everytime i find myself in the nei...  ...  positive\n",
              "25  anytime and everytime i find myself in the nei...  ...  positive\n",
              "26           great food but the service was dreadful!  ...  positive\n",
              "27           great food but the service was dreadful!  ...  negative\n",
              "28  the portions of the food that came out were me...  ...   neutral\n",
              "29  the two waitress's looked like they had been s...  ...  negative\n",
              "30  from the beginning, we were met by friendly st...  ...  positive\n",
              "31  from the beginning, we were met by friendly st...  ...  positive\n",
              "32  we enjoyed ourselves thoroughly and will be go...  ...  positive\n",
              "33  desserts are almost incredible: my personal fa...  ...  positive\n",
              "34  desserts are almost incredible: my personal fa...  ...  positive\n",
              "35  the food was extremely tasty, creatively prese...  ...  positive\n",
              "36  the food was extremely tasty, creatively prese...  ...  positive\n",
              "37   the lasagna was probably the best i have tasted.  ...  positive\n",
              "38  harumi sushi has the freshest and most delicio...  ...  positive\n",
              "39  i highly recommend it for not just its superb ...  ...  positive\n",
              "40  i highly recommend it for not just its superb ...  ...  positive\n",
              "41  i highly recommend it for not just its superb ...  ...  positive\n",
              "42  if you're craving some serious indian food and...  ...  positive\n",
              "43  if you're craving some serious indian food and...  ...  positive\n",
              "44             i definitely enjoyed the food as well.  ...  positive\n",
              "45  it was pleasantly uncrowded, the service was d...  ...  positive\n",
              "46  it was pleasantly uncrowded, the service was d...  ...  positive\n",
              "47  it was pleasantly uncrowded, the service was d...  ...  positive\n",
              "48  it was pleasantly uncrowded, the service was d...  ...  positive\n",
              "49  it was pleasantly uncrowded, the service was d...  ...  positive\n",
              "\n",
              "[50 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "5H6hJfsVo-QK",
        "outputId": "1185d0d6-6361-4a45-8dcf-f3d90415b3fc"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# label_encoder object knows how to understand word labels. \n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "# Encode labels in column 'Country'. \n",
        "df_test['Class']= label_encoder.fit_transform(df_test['Class']) \n",
        "df_test.head()\n",
        "\n",
        "onehotencoder = preprocessing.OneHotEncoder()\n",
        "#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object \n",
        "X = onehotencoder.fit_transform(df_test.Class.values.reshape(-1,1)).toarray()\n",
        "#To add this back into the original dataframe \n",
        "dfOneHot = pd.DataFrame(X, columns = [\"Class_\"+str(int(i)) for i in range(df_test.shape[1])]) \n",
        "df_test = pd.concat([df_test, dfOneHot], axis=1)\n",
        "#droping the country column \n",
        "df_test= df_test.drop(['Class'], axis=1) \n",
        "#printing to verify \n",
        "df_test.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the bread is top notch as well.</td>\n",
              "      <td>bread</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i have to say they have one of the fastest del...</td>\n",
              "      <td>delivery times</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food is always fresh and hot- ready to eat!</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>did i mention that the coffee is outstanding?</td>\n",
              "      <td>coffee</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>certainly not the best sushi in new york, howe...</td>\n",
              "      <td>place</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ... Class_2\n",
              "0                    the bread is top notch as well.  ...     1.0\n",
              "1  i have to say they have one of the fastest del...  ...     1.0\n",
              "2        food is always fresh and hot- ready to eat!  ...     1.0\n",
              "3      did i mention that the coffee is outstanding?  ...     1.0\n",
              "4  certainly not the best sushi in new york, howe...  ...     1.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w0FdSU9nmKWn",
        "outputId": "67b4c1e0-ba0e-442f-f45d-04d44c2b69c8"
      },
      "source": [
        "\n",
        "df_test.info()\n",
        "df_test.head(50)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1120 entries, 0 to 1119\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   text         1120 non-null   object \n",
            " 1   aspect_term  1120 non-null   object \n",
            " 2   Class_0      1120 non-null   float64\n",
            " 3   Class_1      1120 non-null   float64\n",
            " 4   Class_2      1120 non-null   float64\n",
            "dtypes: float64(3), object(2)\n",
            "memory usage: 43.9+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the bread is top notch as well.</td>\n",
              "      <td>bread</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i have to say they have one of the fastest del...</td>\n",
              "      <td>delivery times</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food is always fresh and hot- ready to eat!</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>did i mention that the coffee is outstanding?</td>\n",
              "      <td>coffee</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>certainly not the best sushi in new york, howe...</td>\n",
              "      <td>place</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i trust the people at go sushi, it never disap...</td>\n",
              "      <td>people</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>straight-forward, no surprises, very decent ja...</td>\n",
              "      <td>japanese food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>best spicy tuna roll, great asian salad.</td>\n",
              "      <td>asian salad</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>best spicy tuna roll, great asian salad.</td>\n",
              "      <td>spicy tuna roll</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>try the rose roll (not on menu).</td>\n",
              "      <td>rose roll</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>try the rose roll (not on menu).</td>\n",
              "      <td>menu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>drinks</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>lychee martini</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>in fact, this was not a nicoise salad and was ...</td>\n",
              "      <td>nicoise salad</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>menu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>drinks</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>dessert pizza</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>once we sailed, the top-notch food and live en...</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>once we sailed, the top-notch food and live en...</td>\n",
              "      <td>live entertainment</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>our waiter was horrible; so rude and disintere...</td>\n",
              "      <td>waiter</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>the sangria's - watered down.</td>\n",
              "      <td>sangria</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>menu - uneventful, small.</td>\n",
              "      <td>menu</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>anytime and everytime i find myself in the nei...</td>\n",
              "      <td>sushi</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>anytime and everytime i find myself in the nei...</td>\n",
              "      <td>portions</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>anytime and everytime i find myself in the nei...</td>\n",
              "      <td>price</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>great food but the service was dreadful!</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>great food but the service was dreadful!</td>\n",
              "      <td>service</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>the portions of the food that came out were me...</td>\n",
              "      <td>portions of the food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>the two waitress's looked like they had been s...</td>\n",
              "      <td>waitress's</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>from the beginning, we were met by friendly st...</td>\n",
              "      <td>staff memebers</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>from the beginning, we were met by friendly st...</td>\n",
              "      <td>parking</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>we enjoyed ourselves thoroughly and will be go...</td>\n",
              "      <td>desserts</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>desserts are almost incredible: my personal fa...</td>\n",
              "      <td>desserts</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>desserts are almost incredible: my personal fa...</td>\n",
              "      <td>tart of the day</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>the food was extremely tasty, creatively prese...</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>the food was extremely tasty, creatively prese...</td>\n",
              "      <td>wine</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>the lasagna was probably the best i have tasted.</td>\n",
              "      <td>lasagna</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>harumi sushi has the freshest and most delicio...</td>\n",
              "      <td>array of sushi</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>i highly recommend it for not just its superb ...</td>\n",
              "      <td>cuisine</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>i highly recommend it for not just its superb ...</td>\n",
              "      <td>owners</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>i highly recommend it for not just its superb ...</td>\n",
              "      <td>staff</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>if you're craving some serious indian food and...</td>\n",
              "      <td>indian food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>if you're craving some serious indian food and...</td>\n",
              "      <td>ambiance</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>i definitely enjoyed the food as well.</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>service</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>garden</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>appetizers</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>it was pleasantly uncrowded, the service was d...</td>\n",
              "      <td>entrees</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text  ... Class_2\n",
              "0                     the bread is top notch as well.  ...     1.0\n",
              "1   i have to say they have one of the fastest del...  ...     1.0\n",
              "2         food is always fresh and hot- ready to eat!  ...     1.0\n",
              "3       did i mention that the coffee is outstanding?  ...     1.0\n",
              "4   certainly not the best sushi in new york, howe...  ...     1.0\n",
              "5   i trust the people at go sushi, it never disap...  ...     1.0\n",
              "6   straight-forward, no surprises, very decent ja...  ...     1.0\n",
              "7            best spicy tuna roll, great asian salad.  ...     1.0\n",
              "8            best spicy tuna roll, great asian salad.  ...     1.0\n",
              "9                    try the rose roll (not on menu).  ...     1.0\n",
              "10                   try the rose roll (not on menu).  ...     0.0\n",
              "11  i love the drinks, esp lychee martini, and the...  ...     1.0\n",
              "12  i love the drinks, esp lychee martini, and the...  ...     1.0\n",
              "13  i love the drinks, esp lychee martini, and the...  ...     1.0\n",
              "14  in fact, this was not a nicoise salad and was ...  ...     0.0\n",
              "15  while there's a decent menu, it shouldn't take...  ...     1.0\n",
              "16  while there's a decent menu, it shouldn't take...  ...     0.0\n",
              "17  while there's a decent menu, it shouldn't take...  ...     0.0\n",
              "18  once we sailed, the top-notch food and live en...  ...     1.0\n",
              "19  once we sailed, the top-notch food and live en...  ...     1.0\n",
              "20  our waiter was horrible; so rude and disintere...  ...     0.0\n",
              "21                      the sangria's - watered down.  ...     0.0\n",
              "22                          menu - uneventful, small.  ...     0.0\n",
              "23  anytime and everytime i find myself in the nei...  ...     1.0\n",
              "24  anytime and everytime i find myself in the nei...  ...     1.0\n",
              "25  anytime and everytime i find myself in the nei...  ...     1.0\n",
              "26           great food but the service was dreadful!  ...     1.0\n",
              "27           great food but the service was dreadful!  ...     0.0\n",
              "28  the portions of the food that came out were me...  ...     0.0\n",
              "29  the two waitress's looked like they had been s...  ...     0.0\n",
              "30  from the beginning, we were met by friendly st...  ...     1.0\n",
              "31  from the beginning, we were met by friendly st...  ...     1.0\n",
              "32  we enjoyed ourselves thoroughly and will be go...  ...     1.0\n",
              "33  desserts are almost incredible: my personal fa...  ...     1.0\n",
              "34  desserts are almost incredible: my personal fa...  ...     1.0\n",
              "35  the food was extremely tasty, creatively prese...  ...     1.0\n",
              "36  the food was extremely tasty, creatively prese...  ...     1.0\n",
              "37   the lasagna was probably the best i have tasted.  ...     1.0\n",
              "38  harumi sushi has the freshest and most delicio...  ...     1.0\n",
              "39  i highly recommend it for not just its superb ...  ...     1.0\n",
              "40  i highly recommend it for not just its superb ...  ...     1.0\n",
              "41  i highly recommend it for not just its superb ...  ...     1.0\n",
              "42  if you're craving some serious indian food and...  ...     1.0\n",
              "43  if you're craving some serious indian food and...  ...     1.0\n",
              "44             i definitely enjoyed the food as well.  ...     1.0\n",
              "45  it was pleasantly uncrowded, the service was d...  ...     1.0\n",
              "46  it was pleasantly uncrowded, the service was d...  ...     1.0\n",
              "47  it was pleasantly uncrowded, the service was d...  ...     1.0\n",
              "48  it was pleasantly uncrowded, the service was d...  ...     1.0\n",
              "49  it was pleasantly uncrowded, the service was d...  ...     1.0\n",
              "\n",
              "[50 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2EXq7tmvbxj",
        "outputId": "777e4d7e-cc9d-46bf-e123-70113b9a0a6b"
      },
      "source": [
        "df_test.iloc[217]\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text           waiters are very friendly and the pasta is out...\n",
              "aspect_term                                                pasta\n",
              "Class_0                                                        0\n",
              "Class_1                                                        0\n",
              "Class_2                                                        1\n",
              "Name: 217, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "4HsUY4WEpA4m",
        "outputId": "579bb0ad-e0b3-4a4c-86cd-9fe6e85bac5d"
      },
      "source": [
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/data_2_train.csv')\n",
        "df.head()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>term_location</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3121_0</td>\n",
              "      <td>But the staff was so horrible to us.</td>\n",
              "      <td>staff</td>\n",
              "      <td>8--13</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2777_0</td>\n",
              "      <td>To be completely fair[comma] the only redeemin...</td>\n",
              "      <td>food</td>\n",
              "      <td>57--61</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1634_0</td>\n",
              "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
              "      <td>food</td>\n",
              "      <td>4--8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1634_1</td>\n",
              "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
              "      <td>kitchen</td>\n",
              "      <td>55--62</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1634_2</td>\n",
              "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
              "      <td>menu</td>\n",
              "      <td>141--145</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  example_id  ...  class\n",
              "0     3121_0  ...     -1\n",
              "1     2777_0  ...      1\n",
              "2     1634_0  ...      1\n",
              "3     1634_1  ...      1\n",
              "4     1634_2  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "C8mp0CbjpEAP",
        "outputId": "225daccc-b687-4cc6-fda0-54f20d47c397"
      },
      "source": [
        "\n",
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating == 1:\n",
        "    return 2\n",
        "  elif rating == 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "df['sentiment'] = df[' class'].apply(to_sentiment)\n",
        "\n",
        "#df['sentiment'] = df[' class']\n",
        "class_names = ['negative', 'neutral', 'positive']\n",
        "ax = sns.countplot(df.sentiment)\n",
        "plt.xlabel('review sentiment')\n",
        "ax.set_xticklabels(class_names);\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 410,
              "height": 272
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "2aoA-TwYpHWg",
        "outputId": "d10c437f-2b5b-4caf-fea1-af032e4b0397"
      },
      "source": [
        "df.info()\n",
        "df = df.rename(columns={' text': 'text', ' aspect_term': 'aspect_term', ' term_location': 'term_location', ' example_id': 'example_id', ' class': 'class'})\n",
        "df['text'] = df['text'].apply(lambda x: x.replace('[comma]',',').lower())\n",
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3602 entries, 0 to 3601\n",
            "Data columns (total 6 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   example_id      3602 non-null   object\n",
            " 1    text           3602 non-null   object\n",
            " 2    aspect_term    3602 non-null   object\n",
            " 3    term_location  3602 non-null   object\n",
            " 4    class          3602 non-null   int64 \n",
            " 5   sentiment       3602 non-null   int64 \n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 169.0+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>term_location</th>\n",
              "      <th>class</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3121_0</td>\n",
              "      <td>but the staff was so horrible to us.</td>\n",
              "      <td>staff</td>\n",
              "      <td>8--13</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2777_0</td>\n",
              "      <td>to be completely fair, the only redeeming fact...</td>\n",
              "      <td>food</td>\n",
              "      <td>57--61</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1634_0</td>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>food</td>\n",
              "      <td>4--8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1634_1</td>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>kitchen</td>\n",
              "      <td>55--62</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1634_2</td>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>menu</td>\n",
              "      <td>141--145</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  example_id  ... sentiment\n",
              "0     3121_0  ...         0\n",
              "1     2777_0  ...         2\n",
              "2     1634_0  ...         2\n",
              "3     1634_1  ...         2\n",
              "4     1634_2  ...         1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "YN8vnG4wwPBU",
        "outputId": "999d8b8f-7cc8-4735-c8e1-d886b6b0789d"
      },
      "source": [
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "onehotencoder = preprocessing.OneHotEncoder()\n",
        "#reshape the 1-D country array to 2-D as fit_transform expects 2-D and finally fit the object \n",
        "X = onehotencoder.fit_transform(df.sentiment.values.reshape(-1,1)).toarray()\n",
        "#To add this back into the original dataframe \n",
        "df= df.drop(['example_id'], axis=1)\n",
        "df= df.drop(['class'], axis=1)\n",
        "df= df.drop(['term_location'], axis=1)\n",
        "dfOneHot = pd.DataFrame(X, columns = [\"Class_\"+str(int(i)) for i in range(df.shape[1])]) \n",
        "df = pd.concat([df, dfOneHot], axis=1)\n",
        "#droping the country column \n",
        "df= df.drop(['sentiment'], axis=1) \n",
        "#printing to verify \n",
        "df.head()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>but the staff was so horrible to us.</td>\n",
              "      <td>staff</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>to be completely fair, the only redeeming fact...</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>food</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>kitchen</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>menu</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ... Class_2\n",
              "0               but the staff was so horrible to us.  ...     0.0\n",
              "1  to be completely fair, the only redeeming fact...  ...     1.0\n",
              "2  the food is uniformly exceptional, with a very...  ...     1.0\n",
              "3  the food is uniformly exceptional, with a very...  ...     1.0\n",
              "4  the food is uniformly exceptional, with a very...  ...     0.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "YXfhVnr7yZ31",
        "outputId": "0578b62c-3a2c-44c4-e3cf-98996948adcf"
      },
      "source": [
        "df_test['list'] = df_test[df_test.columns[2:]].values.tolist()\n",
        "new_df_test = df_test[['text', 'aspect_term', 'list']].copy()\n",
        "new_df_test.head(20)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the bread is top notch as well.</td>\n",
              "      <td>bread</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i have to say they have one of the fastest del...</td>\n",
              "      <td>delivery times</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food is always fresh and hot- ready to eat!</td>\n",
              "      <td>food</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>did i mention that the coffee is outstanding?</td>\n",
              "      <td>coffee</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>certainly not the best sushi in new york, howe...</td>\n",
              "      <td>place</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i trust the people at go sushi, it never disap...</td>\n",
              "      <td>people</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>straight-forward, no surprises, very decent ja...</td>\n",
              "      <td>japanese food</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>best spicy tuna roll, great asian salad.</td>\n",
              "      <td>asian salad</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>best spicy tuna roll, great asian salad.</td>\n",
              "      <td>spicy tuna roll</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>try the rose roll (not on menu).</td>\n",
              "      <td>rose roll</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>try the rose roll (not on menu).</td>\n",
              "      <td>menu</td>\n",
              "      <td>[0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>drinks</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>lychee martini</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>i love the drinks, esp lychee martini, and the...</td>\n",
              "      <td>food</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>in fact, this was not a nicoise salad and was ...</td>\n",
              "      <td>nicoise salad</td>\n",
              "      <td>[1.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>menu</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>drinks</td>\n",
              "      <td>[0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>while there's a decent menu, it shouldn't take...</td>\n",
              "      <td>dessert pizza</td>\n",
              "      <td>[0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>once we sailed, the top-notch food and live en...</td>\n",
              "      <td>food</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>once we sailed, the top-notch food and live en...</td>\n",
              "      <td>live entertainment</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text  ...             list\n",
              "0                     the bread is top notch as well.  ...  [0.0, 0.0, 1.0]\n",
              "1   i have to say they have one of the fastest del...  ...  [0.0, 0.0, 1.0]\n",
              "2         food is always fresh and hot- ready to eat!  ...  [0.0, 0.0, 1.0]\n",
              "3       did i mention that the coffee is outstanding?  ...  [0.0, 0.0, 1.0]\n",
              "4   certainly not the best sushi in new york, howe...  ...  [0.0, 0.0, 1.0]\n",
              "5   i trust the people at go sushi, it never disap...  ...  [0.0, 0.0, 1.0]\n",
              "6   straight-forward, no surprises, very decent ja...  ...  [0.0, 0.0, 1.0]\n",
              "7            best spicy tuna roll, great asian salad.  ...  [0.0, 0.0, 1.0]\n",
              "8            best spicy tuna roll, great asian salad.  ...  [0.0, 0.0, 1.0]\n",
              "9                    try the rose roll (not on menu).  ...  [0.0, 0.0, 1.0]\n",
              "10                   try the rose roll (not on menu).  ...  [0.0, 1.0, 0.0]\n",
              "11  i love the drinks, esp lychee martini, and the...  ...  [0.0, 0.0, 1.0]\n",
              "12  i love the drinks, esp lychee martini, and the...  ...  [0.0, 0.0, 1.0]\n",
              "13  i love the drinks, esp lychee martini, and the...  ...  [0.0, 0.0, 1.0]\n",
              "14  in fact, this was not a nicoise salad and was ...  ...  [1.0, 0.0, 0.0]\n",
              "15  while there's a decent menu, it shouldn't take...  ...  [0.0, 0.0, 1.0]\n",
              "16  while there's a decent menu, it shouldn't take...  ...  [0.0, 1.0, 0.0]\n",
              "17  while there's a decent menu, it shouldn't take...  ...  [0.0, 1.0, 0.0]\n",
              "18  once we sailed, the top-notch food and live en...  ...  [0.0, 0.0, 1.0]\n",
              "19  once we sailed, the top-notch food and live en...  ...  [0.0, 0.0, 1.0]\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "r-WOXKcVyZni",
        "outputId": "71cf4189-a2da-4638-84ac-d0a2eae8ca93"
      },
      "source": [
        "df['list'] = df[df.columns[2:]].values.tolist()\n",
        "new_df = df[['text', 'aspect_term', 'list']].copy()\n",
        "new_df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>aspect_term</th>\n",
              "      <th>list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>but the staff was so horrible to us.</td>\n",
              "      <td>staff</td>\n",
              "      <td>[1.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>to be completely fair, the only redeeming fact...</td>\n",
              "      <td>food</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>food</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>kitchen</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the food is uniformly exceptional, with a very...</td>\n",
              "      <td>menu</td>\n",
              "      <td>[0.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...             list\n",
              "0               but the staff was so horrible to us.  ...  [1.0, 0.0, 0.0]\n",
              "1  to be completely fair, the only redeeming fact...  ...  [0.0, 0.0, 1.0]\n",
              "2  the food is uniformly exceptional, with a very...  ...  [0.0, 0.0, 1.0]\n",
              "3  the food is uniformly exceptional, with a very...  ...  [0.0, 0.0, 1.0]\n",
              "4  the food is uniformly exceptional, with a very...  ...  [0.0, 1.0, 0.0]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7V4T0RupWue",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "3fdc2470c953429ca98df0a667a59f52",
            "527ebc6c429c4f33abd61b176fb1797b",
            "b6956b02e014492cbdf2577cd82a941c",
            "4385c2146bac48cbb3eca5f8d6b35d3c",
            "920f352577ee4f02bdb2b931e4442f45",
            "cb64f2371ebf405bbb34a2ac6db3d428",
            "51eec80b667145a2b963cd3802af3164",
            "8f7d03db90304e91abc6e8c7d27b547e",
            "f0cae6134c38406a99b5f00a3a2afc0e",
            "39f6103c61224fac8db9829318d5fff8",
            "cd237248c0f84ff1aa8849056f806390",
            "0215105f62af4f43877c253dc2731cc6",
            "0ce5dcead073466fae08a02789511777",
            "421e40fe86ad4d50a611fbafd3486bb4",
            "76e728feac1a45ddac2fa7d8399dcf8a",
            "a62b5923794d4030a7960ad05fb6e205",
            "97ade3ca6db94712acb8c5b7564da52b",
            "3a919708b5884846a54197e49a0bdae9",
            "8542730f21444177b243862e5994f808",
            "6ad6c29519f44beb999ef2e09cf008d8",
            "0dba1678a2004122ad3a090d18f67334",
            "e2dae36d666f4cadab6d086d5d020d8d",
            "3adb285bf1aa4557b7bf2ffe32ce0c02",
            "bff65a15b594473eae624ec3ea74017f"
          ]
        },
        "outputId": "2b9061b1-3dfc-40b0-dfde-6971f1b73269"
      },
      "source": [
        "# Sections of config\n",
        "\n",
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 100\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 5\n",
        "#epochs = 3\n",
        "LEARNING_RATE = 2e-05\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',return_dict=False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fdc2470c953429ca98df0a667a59f52",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0cae6134c38406a99b5f00a3a2afc0e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97ade3ca6db94712acb8c5b7564da52b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jAli2nfpJzx"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.aspect_term = dataframe.aspect_term\n",
        "        self.targets = self.data.list\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "        aspect_term = str(self.aspect_term[index])\n",
        "        aspect_term = \" \".join(aspect_term.split())\n",
        "        #print(text)\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            aspect_term,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1j8XIrmpQbH",
        "outputId": "1d31c0fe-33da-43de-97ec-82daa2b531b1"
      },
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "train_size = 1.00\n",
        "test_size = 0.50\n",
        "train_dataset=new_df.sample(frac=train_size,random_state=200)\n",
        "test_dataset=new_df_test.sample(frac=test_size,random_state=200)\n",
        "valid_dataset=new_df_test.drop(test_dataset.index).reset_index(drop=True)\n",
        "test_dataset = test_dataset.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"VALID Dataset: {}\".format(valid_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "validing_set = CustomDataset(valid_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL Dataset: (3602, 6)\n",
            "TRAIN Dataset: (3602, 3)\n",
            "VALID Dataset: (560, 3)\n",
            "TEST Dataset: (560, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__PM_crE0twH"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0,\n",
        "                \n",
        "                }\n",
        "\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "dev_loader = DataLoader(validing_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "56eccfed00274f89b22d7380b7e33de0",
            "268a9afe72d742bebef9b36c9189df4e",
            "c39dd5bfe3ec4de2adcb7e2e7d86cc1b",
            "2d28b2117a304fcb87f645d672b95bc0",
            "4e6404706ca94e79bfdf6f7d3277c786",
            "2af6ca4c8479420489a805a811cef2a6",
            "9b56b2feec154cdda7d9776ebbf8d398",
            "28411a1669bf4c609ed48dc2318362ef",
            "279fbc4b754e4645b9a8a90dcabb4717",
            "a66ad1c0c775479eaf1efa189b84cd80",
            "a2fea0e68d7c4554b3dc97c384edd2ef",
            "a1d6d6c52d4344f98a91b757dba28236",
            "9878e513ab1148a8b4e660d6e460c67a",
            "936369bc406a4a0893ab8cb271a2a1cc",
            "eeae0ec8513d4a86918c57d58f21bea9",
            "7202124401ca40668df1e084efcb7cf3"
          ]
        },
        "id": "36wRZnSurPZ3",
        "outputId": "08cc837a-29ef-48d3-e46f-8897071c20e9"
      },
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
        "\n",
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "        self.l2 = torch.nn.Dropout(0.3)\n",
        "        self.l3 = torch.nn.Linear(768, 3)\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, pooled_output= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "        output_2 = self.l2(pooled_output)\n",
        "        output = self.l3(output_2)\n",
        "        return output\n",
        "\n",
        "fchidden = 256\n",
        "hiddendim_lstm = 256\n",
        "embeddim = 768\n",
        "numlayers = 12\n",
        "numclasses = 3\n",
        "num_heads = 2\n",
        "\n",
        "class Bert_LSTM(torch.nn.Module):\n",
        "    def __init__(self, numclasses):\n",
        "        super(Bert_LSTM, self).__init__()\n",
        "        self.numclasses = numclasses\n",
        "        self.embeddim = embeddim\n",
        "        self.numlayers = numlayers\n",
        "        self.hiddendim_lstm = hiddendim_lstm\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "        print(\"BERT Model Loaded\")\n",
        "        self.lstm = torch.nn.LSTM(self.embeddim, self.hiddendim_lstm, bidirectional = False, batch_first=True) # noqa\n",
        "        self.fc = torch.nn.Linear(self.hiddendim_lstm, self.numclasses)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "      last_hidden_state, pooled_output = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "      #print(last_hidden_state.shape)\n",
        "      #print(pooled_output.shape)\n",
        "      out, _ = self.lstm(last_hidden_state, None)\n",
        "      #print(out.shape)\n",
        "      out = self.dropout(out[:, -1, :])\n",
        "      print(out.shape)\n",
        "      out = self.fc(out)\n",
        "      return out\n",
        "\n",
        "\n",
        "\n",
        "class Bert_LAttentionM(torch.nn.Module):\n",
        "    def __init__(self, numclasses):\n",
        "        super(Bert_LAttentionM, self).__init__()\n",
        "        self.numclasses = numclasses\n",
        "        self.embeddim = embeddim\n",
        "        self.numlayers = numlayers\n",
        "        self.hiddendim_lstm = hiddendim_lstm\n",
        "        self.fchidden = fchidden\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "        print(\"BERT Model Loaded\")\n",
        "        q_t = np.random.normal(loc=0.0, scale=0.1, size=(1, self.embeddim))\n",
        "        self.q = nn.Parameter(torch.from_numpy(q_t)).float().to(device)\n",
        "        w_ht = np.random.normal(loc=0.0, scale=0.1, size=(self.embeddim, self.fchidden)) # noqa\n",
        "        self.w_h = nn.Parameter(torch.from_numpy(w_ht)).float().to(device)\n",
        "\n",
        "        self.fc = nn.Linear(self.fchidden, self.numclasses)\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "      last_hidden_state, pooled_output = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "      #print(last_hidden_state.shape)\n",
        "      #print(pooled_output.shape)\n",
        "      att = self.attention(last_hidden_state)\n",
        "      #print(\"3\",att.shape)\n",
        "      out = self.dropout(att)\n",
        "      out = self.fc(out)\n",
        "      #print(\"la\",out.shape)\n",
        "      return out\n",
        "\n",
        "    def attention(self, h):\n",
        "        #print(\"hhhhh\",h.shape)\n",
        "        v = torch.matmul(self.q, h.transpose(-2, -1)).squeeze(1)\n",
        "        v = torch.nn.functional.softmax(v, -1)\n",
        "        v_temp = torch.matmul(v.unsqueeze(1), h).transpose(-2, -1)\n",
        "        #print(\"tem\",v_temp.shape)\n",
        "        v = torch.matmul(self.w_h.transpose(1, 0), v_temp).squeeze(2)\n",
        "        #print(v.shape)\n",
        "        return v\n",
        "\n",
        "class Bert_Attention(torch.nn.Module):\n",
        "    def __init__(self, numclasses, device):\n",
        "        super(Bert_Attention, self).__init__()\n",
        "        self.numclasses = numclasses\n",
        "        self.embeddim = embeddim\n",
        "        self.numlayers = numlayers\n",
        "        self.hiddendim_lstm = hiddendim_lstm\n",
        "        self.fchidden = fchidden\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "        print(\"BERT Model Loaded\")\n",
        "        self.Gru = torch.nn.LSTM(self.embeddim, self.hiddendim_lstm, bidirectional = True, batch_first=True)\n",
        "\n",
        "        q_t = np.random.normal(loc=0.0, scale=0.1, size=(1, self.hiddendim_lstm*2))\n",
        "        self.q = torch.nn.Parameter(torch.from_numpy(q_t)).float().to(device)\n",
        "        w_ht = np.random.normal(loc=0.0, scale=0.1, size=(self.hiddendim_lstm*2, self.fchidden)) # noqa\n",
        "        self.w_h = torch.nn.Parameter(torch.from_numpy(w_ht)).float().to(device)\n",
        "\n",
        "        self.fc = torch.nn.Linear(self.fchidden, self.numclasses)\n",
        "\n",
        "    def forward(self, inp_ids, att_mask, token_ids):\n",
        "        last_hidden_state, pooler_output = self.bert(input_ids=inp_ids, attention_mask=att_mask, token_type_ids=token_ids)\n",
        "        #print(\"1\",last_hidden_state.shape)\n",
        "        out, _ = self.Gru(last_hidden_state, None)\n",
        "        #print(\"2\",out.shape)\n",
        "        #out = self.attention(out)\n",
        "        att = self.attention(out)\n",
        "        #print(\"3\",att.shape)\n",
        "        out = self.dropout(att)\n",
        "        out = self.fc(out)\n",
        "        #print(\"la\",out.shape)\n",
        "        return out\n",
        "\n",
        "    def attention(self, h):\n",
        "        #print(\"hhhhh\",h.shape)\n",
        "        v = torch.matmul(self.q, h.transpose(-2, -1)).squeeze(1)\n",
        "        v = torch.nn.functional.softmax(v, -1)\n",
        "        v_temp = torch.matmul(v.unsqueeze(1), h).transpose(-2, -1)\n",
        "        #print(\"tem\",v_temp.shape)\n",
        "        v = torch.matmul(self.w_h.transpose(1, 0), v_temp).squeeze(2)\n",
        "        #print(v.shape)\n",
        "        return v\n",
        "\n",
        "\n",
        "#model = Bert_Attention(numclasses, device)\n",
        "#model = Bert_LAttentionM(numclasses)\n",
        "model = Bert_LSTM(numclasses)\n",
        "#model = BERTClass()\n",
        "model.to(device)\n",
        "model"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56eccfed00274f89b22d7380b7e33de0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "279fbc4b754e4645b9a8a90dcabb4717",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "BERT Model Loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bert_LSTM(\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (lstm): LSTM(768, 256, batch_first=True)\n",
              "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Wt5eiSrTU9"
      },
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8MAvbovrqDn"
      },
      "source": [
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDmlWz2QoTaY"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate(loader, model, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        loss = 0.0\n",
        "        y_pred = []\n",
        "        y_true = []\n",
        "        for _,data in enumerate(loader, 0):              \n",
        "            #print(data)\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            #if _%5000==0:\n",
        "              #print(f'Epoch: {numepochs}, Loss:  {loss.item()}')\n",
        "            preds = torch.sigmoid(outputs)\n",
        "            y_pred.extend(preds.tolist())\n",
        "            y_true.extend(targets.tolist())\n",
        "            y_predict = np.array(y_pred) >= 0.5\n",
        "\n",
        "        F1 = round((f1_score(y_true, y_predict, average='macro')), 2) * 100\n",
        "        return loss, F1"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjuVU2hboNB0"
      },
      "source": [
        "import copy\n",
        "\n",
        "def train_model(training_loader, dev_loader, test_loader, model,\n",
        "                numclasses, numepochs, runs, device):\n",
        "    \"\"\" Trains the neural network\n",
        "    Arguments:\n",
        "    train_loader (DataLoader): Training Data Loader\n",
        "    dev_loader (DataLoader): Validation Data Loader\n",
        "    test_loader (DataLoader): Test Data Loader\n",
        "    model_name (str): Name of the model to train\n",
        "    numclasses (int): Number of classes in the data\n",
        "    numepochs (int): Number of epochs to train\n",
        "    runs (int): Number of runs to report averaged results\n",
        "    device (torch.device): Device type\n",
        "    \"\"\"\n",
        "    avg_testacc = 0.0\n",
        "    avg_testf1 = 0.0\n",
        "    for run in range(1, runs+1):\n",
        "        print(\"Training for run {} \".format(run))\n",
        "        print(\"--------------------------------------------\")\n",
        "        \n",
        "        model.train()\n",
        "        valbest = 0.0\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        for epoch in range(1, numepochs+1):\n",
        "            model.train()\n",
        "            for _,data in enumerate(training_loader, 0):              \n",
        "            #print(data)\n",
        "                ids = data['ids'].to(device, dtype = torch.long)\n",
        "                mask = data['mask'].to(device, dtype = torch.long)\n",
        "                token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "                targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "                model.zero_grad()\n",
        "                outputs = model(ids, mask, token_type_ids)\n",
        "                loss = loss_fn(outputs, targets)\n",
        "                #if _%5000==0:\n",
        "                  #print(f'Epoch: {numepochs}, Loss:  {loss.item()}')\n",
        "            \n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            valloss, valacc = evaluate(dev_loader, model, device) # noqa\n",
        "            if(valacc > valbest):\n",
        "                valbest = valacc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            print(\" Val Loss {} Val Acc {} \".format(valloss,\n",
        "                                                            valacc))\n",
        "\n",
        "        model.load_state_dict(best_model_wts)\n",
        "\n",
        "        curtestloss, curtestf1 = evaluate(testing_loader, model, device)\n",
        "        print(\"Run {}  F1 Score {}\".format(run, curtestf1))\n",
        "        print(\"---------------------------------------------------\")\n",
        "        #avg_testacc += curtestacc\n",
        "        avg_testf1 += curtestf1\n",
        "\n",
        "    print(\"Average  F1: {} \".format(avg_testf1/runs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaoxKkU0oVpD",
        "outputId": "e3376001-3f7a-4e06-a5c0-f91130b3db55"
      },
      "source": [
        "train_model(training_loader, dev_loader, testing_loader, model, 3, EPOCHS, EPOCHS, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training for run 1 \n",
            "--------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Val Loss 0.2702678143978119 Val Acc 62.0 \n",
            " Val Loss 0.3136621117591858 Val Acc 68.0 \n",
            " Val Loss 0.35744425654411316 Val Acc 68.0 \n",
            " Val Loss 0.4051930904388428 Val Acc 75.0 \n",
            " Val Loss 0.33246326446533203 Val Acc 70.0 \n",
            "Run 1  F1 Score 74.0\n",
            "---------------------------------------------------\n",
            "Training for run 2 \n",
            "--------------------------------------------\n",
            " Val Loss 0.34715351462364197 Val Acc 76.0 \n",
            " Val Loss 0.3761938512325287 Val Acc 69.0 \n",
            " Val Loss 0.8095970153808594 Val Acc 76.0 \n",
            " Val Loss 0.005316784605383873 Val Acc 73.0 \n",
            " Val Loss 0.1846476048231125 Val Acc 75.0 \n",
            "Run 2  F1 Score 75.0\n",
            "---------------------------------------------------\n",
            "Training for run 3 \n",
            "--------------------------------------------\n",
            " Val Loss 0.36768001317977905 Val Acc 73.0 \n",
            " Val Loss 0.46229299902915955 Val Acc 75.0 \n",
            " Val Loss 0.41605430841445923 Val Acc 74.0 \n",
            " Val Loss 0.15644201636314392 Val Acc 74.0 \n",
            " Val Loss 0.5778172016143799 Val Acc 74.0 \n",
            "Run 3  F1 Score 75.0\n",
            "---------------------------------------------------\n",
            "Training for run 4 \n",
            "--------------------------------------------\n",
            " Val Loss 0.06998766958713531 Val Acc 76.0 \n",
            " Val Loss 0.1558442860841751 Val Acc 75.0 \n",
            " Val Loss 0.3820793330669403 Val Acc 77.0 \n",
            " Val Loss 0.12585294246673584 Val Acc 75.0 \n",
            " Val Loss 0.2040744423866272 Val Acc 76.0 \n",
            "Run 4  F1 Score 75.0\n",
            "---------------------------------------------------\n",
            "Training for run 5 \n",
            "--------------------------------------------\n",
            " Val Loss 0.6177564859390259 Val Acc 72.0 \n",
            " Val Loss 0.956929087638855 Val Acc 78.0 \n",
            " Val Loss 0.31655800342559814 Val Acc 72.0 \n",
            " Val Loss 0.8566846251487732 Val Acc 79.0 \n",
            " Val Loss 0.8161147832870483 Val Acc 78.0 \n",
            "Run 5  F1 Score 79.0\n",
            "---------------------------------------------------\n",
            "Average  F1: 75.6 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Qw9ZkHrsHl"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        #print(data)\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        #print(outputs.shape)\n",
        "        #print(targets.shape)\n",
        "        #print(outputs.dtype)\n",
        "        #print(targets.dtype)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        if _%5000==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        #optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mGn2zejrulf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6781e23d-cf3c-4f5a-9dde-114db5681e12"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 256])\n",
            "Epoch: 0, Loss:  0.7055748701095581\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([2, 256])\n",
            "torch.Size([16, 256])\n",
            "Epoch: 1, Loss:  0.3873770833015442\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([2, 256])\n",
            "torch.Size([16, 256])\n",
            "Epoch: 2, Loss:  0.13069921731948853\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([2, 256])\n",
            "torch.Size([16, 256])\n",
            "Epoch: 3, Loss:  0.1311332881450653\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([2, 256])\n",
            "torch.Size([16, 256])\n",
            "Epoch: 4, Loss:  0.04364310950040817\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([16, 256])\n",
            "torch.Size([2, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wep_15F993GH"
      },
      "source": [
        "def validation(epoch):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float) \n",
        "            #print(targets.shape)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tc4Szu4kO6O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV7gJOVp4m72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "441c6b5a-88fd-4a68-9a8a-05dcb3204b4c"
      },
      "source": [
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    outputs, targets = validation(epoch)\n",
        "    outputs = np.array(outputs) >= 0.5\n",
        "    accuracy = metrics.accuracy_score(targets, outputs)\n",
        "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "    precision_score_micro = metrics.precision_score(targets, outputs, average='micro')\n",
        "    precision_score_macro = metrics.precision_score(targets, outputs, average='macro')\n",
        "    recall_score_micro = metrics.recall_score(targets, outputs, average='micro')\n",
        "    recall_score_macro = metrics.recall_score(targets, outputs, average='macro')\n",
        "    print(f\"Accuracy Score = {accuracy}\")\n",
        "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
        "    print(f\"precision_score (Micro) = {precision_score_micro}\")\n",
        "    print(f\"precision_score (Macro) = {precision_score_macro}\")\n",
        "    print(f\"recall_score (Micro) = {recall_score_micro}\")\n",
        "    print(f\"recall_score (Macro) = {recall_score_macro}\")\n",
        "    if accuracy > best_accuracy:\n",
        "      torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "      best_accuracy = accuracy"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "Accuracy Score = 0.8464285714285714\n",
            "F1 Score (Micro) = 0.8555956678700362\n",
            "F1 Score (Macro) = 0.7844320077894538\n",
            "precision_score (Micro) = 0.864963503649635\n",
            "precision_score (Macro) = 0.821213153943417\n",
            "recall_score (Micro) = 0.8464285714285714\n",
            "recall_score (Macro) = 0.7782115259699581\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "Accuracy Score = 0.8464285714285714\n",
            "F1 Score (Micro) = 0.8555956678700362\n",
            "F1 Score (Macro) = 0.7844320077894538\n",
            "precision_score (Micro) = 0.864963503649635\n",
            "precision_score (Macro) = 0.821213153943417\n",
            "recall_score (Micro) = 0.8464285714285714\n",
            "recall_score (Macro) = 0.7782115259699581\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "Accuracy Score = 0.8464285714285714\n",
            "F1 Score (Micro) = 0.8555956678700362\n",
            "F1 Score (Macro) = 0.7844320077894538\n",
            "precision_score (Micro) = 0.864963503649635\n",
            "precision_score (Macro) = 0.821213153943417\n",
            "recall_score (Micro) = 0.8464285714285714\n",
            "recall_score (Macro) = 0.7782115259699581\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "Accuracy Score = 0.8464285714285714\n",
            "F1 Score (Micro) = 0.8555956678700362\n",
            "F1 Score (Macro) = 0.7844320077894538\n",
            "precision_score (Micro) = 0.864963503649635\n",
            "precision_score (Macro) = 0.821213153943417\n",
            "recall_score (Micro) = 0.8464285714285714\n",
            "recall_score (Macro) = 0.7782115259699581\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "Accuracy Score = 0.8464285714285714\n",
            "F1 Score (Micro) = 0.8555956678700362\n",
            "F1 Score (Macro) = 0.7844320077894538\n",
            "precision_score (Micro) = 0.864963503649635\n",
            "precision_score (Macro) = 0.821213153943417\n",
            "recall_score (Micro) = 0.8464285714285714\n",
            "recall_score (Macro) = 0.7782115259699581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9sqpt6PK9p6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91461eeb-f77e-4a0e-b587-07b0eba5ac17"
      },
      "source": [
        "class_names = ['Negative', 'Neutral', 'Positive']\n",
        "print(classification_report(outputs, targets, target_names=class_names))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.89      0.72      0.80       114\n",
            "     Neutral       0.51      0.83      0.63        64\n",
            "    Positive       0.93      0.92      0.92       370\n",
            "\n",
            "   micro avg       0.85      0.86      0.86       548\n",
            "   macro avg       0.78      0.82      0.78       548\n",
            "weighted avg       0.87      0.86      0.86       548\n",
            " samples avg       0.85      0.85      0.85       548\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF-WViMk-HBJ"
      },
      "source": [
        "#class_names = ['Class_0', 'Class_1', 'Class_2']\n",
        "\n",
        "class_names = ['Negative', 'Neutral', 'Positive']\n",
        "#test_string = \"The shells were crisp and authentic, the filling was real ricotta cheese, not the fake junk a lot of Italian Places use these days.\"\n",
        "#test_string = \"The pizza and garlic bread are good, but the staff members are rude to us.\"\n",
        "test_string = \"The pizza and pasta are delicious, but the taste of garlic bread is not good.\"\n",
        "#at = \"staff members\"\n",
        "#at = \"garlic bread\"\n",
        "at = \"pasta\"\n",
        "#at = \"food\"\n",
        "#at = \"Italian Places\"\n",
        "\n",
        "inputs = tokenizer.encode_plus(\n",
        "            test_string,\n",
        "            at,\n",
        "            add_special_tokens=True,\n",
        "            max_length=80,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors='pt',\n",
        ")\n",
        "\n",
        "input_ids = inputs['input_ids'].to(device)\n",
        "mask = inputs['attention_mask'].to(device)\n",
        "token_type_ids = inputs[\"token_type_ids\"].to(device)\n",
        "print(input_ids)\n",
        "print(mask)\n",
        "print(token_type_ids)\n",
        "\n",
        "target,  = model(input_ids, mask, token_type_ids)\n",
        "#output = model(input_ids, attention_mask)\n",
        "\n",
        "predict = torch.sigmoid(target)\n",
        "print(predict)\n",
        "\n",
        "predict = predict.cpu().detach().flatten().numpy()\n",
        "predictlabel = []\n",
        "\n",
        "for i, labelname in enumerate(class_names):\n",
        "  labelprob = predict[i]\n",
        "  if labelprob > 0.5:\n",
        "    predictlabel.append(labelname)\n",
        "predictlabel\n",
        "\n",
        "print(predictlabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8Lt5wVVyH_n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}